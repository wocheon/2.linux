# 인공지능(AI) 전체 구조와 최신 주요 분류

## 구조 요약 (트리 도식)

```txt
인공지능 (AI)
├── 머신 러닝 (Machine Learning)
|    ├── 지도 학습 (Supervised)
|    ├── 비지도 학습 (Unsupervised)
|    ├── 준지도 학습 (Semi-supervised)
|    ├── 자기 지도 학습 (Self-supervised)
|    ├── 강화 학습 (Reinforcement)
|    ├── 전이 학습 (Transfer Learning)
|    └── AutoML
├── 딥 러닝 (Deep Learning)
|    ├── 신경망 (Neural Networks)
|        ├── 합성곱 신경망 (CNN)
|        ├── 순환 신경망 (RNN)
|        ├── 그래프 신경망 (GNN)
|        └── 트랜스포머 (Transformer)
├── 대규모 언어 모델 (LLM)
|    ├── 컨텍스트 학습 (In-context Learning)
|    ├── 프로프트 엔지니어링 (Prompt Engineering)
|    └── Fine-tuning
├── 생성형 AI (Generative AI)
|    ├── 멀티모달 AI (Multimodal AI)
|    ├── 소규모 언어 모델 (SLM)
|    └── Alignment(정렬)
└── Agent AI (지능형 에이전트)
└── 연합 학습 (Federated Learning)
└── 설명가능한 AI (XAI)
```

## 인공지능 (Artificial Intelligence, AI)

- **정의**: 인간과 유사한 지능적 작업(학습, 추론, 문제 해결 등)을 컴퓨터가 수행하도록 만드는 다양한 기술과 알고리즘의 총칭

***

## AX (AI Transformation, 인공지능 전환)
- 정의: AI를 단순한 도구 수준을 넘어, 기업과 사회 운영 전반에 깊이 통합해 전면적 혁신을 이루는 과정

- 특징:
    - 기존 디지털 전환(DX)을 넘어 AI가 의사결정, 업무 실행, 비즈니스 모델 혁신에 중심적 역할 수행
    - AI가 판단, 실행, 개선까지 스스로 수행하여 지능화된 생태계 창출
    - 기업 운영, 제품·서비스 제공, 조직 문화, 고객 경험 등 모든 분야에 AI 적용 확대

- 의의: AI 기반의 차세대 혁명으로, 비즈니스 및 사회 구조를 지능형으로 재편

***

### 머신 러닝 (Machine Learning)

- **개념**: **데이터로부터 패턴을 학습**해 명시적 프로그래밍 없이 작업을 수행하는 기술
- **주요 확장 개념**:
    - **전이 학습 (Transfer Learning)**: 이미 학습된 모델의 지식을 새로운 과제에 적용해서 적은 데이터로도 우수한 성능을 달성
    - **AutoML**: 데이터 처리부터 모델 최적화까지 머신러닝 전체 과정을 자동화하는 시스템
    
#### 1. 지도 학습 (Supervised Learning)
- **정답(레이블)이** 주어진 데이터로 입력과 출력의 관계를 학습  
- **예시**: 스팸 메일 분류, 이미지 인식

#### 2. 비지도 학습 (Unsupervised Learning)
- **정답(레이블) 없이** 데이터 내 구조나 패턴을 탐색  
- **예시**: 군집화, 차원 축소

#### 3. 준지도 학습 (Semi-supervised Learning)
- **적은 양의 레이블 데이터와 많은 비레이블 데이터를 함께 활용**  
- **활용**: 라벨링 비용이 큰 환경에서 성능 개선

#### 4. 자기 지도 학습 (Self-supervised Learning)
- **데이터 내 일부 정보를 감추고 이를 예측하도록 학습**  
- **특징**: 대규모 언어/비전 모델에서 사전학습의 핵심 기법

#### 5. 강화 학습 (Reinforcement Learning)
- **에이전트**가 환경과 상호작용하며 보상을 최대화하도록 행동을 선택하는 학습 방식  
- **예시**: 게임 플레이, 자율 주행

***

### 딥 러닝 (Deep Learning)

- **정의**: 다층 신경망(Deep Neural Network)으로 복잡하고 계층적인 패턴 학습  
- **세부 구조**:
    - **신경망 (Neural Networks)**: 입력층~은닉층~출력층의 계층적 구조
        - **합성곱 신경망 (CNN)**: 이미지/영상 등 격자형 데이터 특징 추출
        - **순환 신경망 (RNN)**: 시퀀스(연속 데이터) 처리, 자연어·시계열 분석
        - **그래프 신경망 (GNN)**: 그래프 구조(노드/엣지) 데이터에서 관계와 패턴 학습
        - **트랜스포머 (Transformer)**: 대용량 데이터의 시퀀스·자연어처리(LM, LLM 등)에서 사용되는 혁신적 구조

***

### 대규모 언어 모델 및 생성형 AI

- **대규모 언어 모델 (LLM, Large Language Models)**
    - **정의**: 방대한 텍스트로 학습해 언어 이해·생성이 가능한 신경망 기반 모델
    - **예시**: GPT, BERT, ChatGPT
    - **세부 기술**:
        - **컨텍스트 학습 (In-context Learning)**: 파인튜닝 없이도 입력된 사례만 토대로 태스크 수행 가능
        - **프로프트 엔지니어링 (Prompt Engineering)**: LLM을 효과적으로 활용하기 위한 프롬프트 최적화 및 설계 기법

- **생성형 AI (Generative AI)**
    - **개념**: 텍스트, 이미지, 음성 등 다양한 콘텐츠를 생성
    - **특징**: 기존 자료를 바탕으로 새롭고 창의적인 결과물 생성  
    - **세부 분야**:
        - **멀티모달 AI (Multimodal AI)**: 텍스트·이미지·음성 등 여러 데이터 타입을 동시에 이해하고 생성
        - **소규모 언어 모델 (SLM, Small Language Models)**: 제한된 리소스 환경에 적합한 경량 LLM
    - **정렬 (Alignment)**: 생성 AI가 인간의 의도, 윤리 기준 등에 맞게 출력을 조정, 최적화하는 연구와 기술

- **Agent AI (지능형 에이전트)**
    - **정의**: 환경과 상호작용하며 목표를 달성하기 위해 스스로 판단하고 행동하는 자동화된 지능 시스템
    - **예시**: AI 비서, 업무 자동화 로봇, 게임 내 지능형 캐릭터

- **파인튜닝 (Fine-tuning)**
    - **개념**: 사전학습된 모델을 특정 과제·도메인에 맞게 추가 학습
    - **활용**: 기업 맞춤 챗봇, 의료·법률 전문 모델

***

### 기타 추천 및 최신 AI 기술

- **연합 학습 (Federated Learning)**
    - 데이터 자체는 로컬 기기(스마트폰 등)에 남기고, 모델만 중앙 서버와 공유해 학습함  
    - **특징**: 개인정보 보호, 분산 환경의 모델 학습

- **설명가능한 AI (Explainable AI, XAI)**
    - AI의 판단 근거나 과정을 이해하고 설명할 수 있도록 지원

***

## AI 모델 분류 기준

- 엔지니어링 환경(인프라) 모델의 체급을 기준으로 분류 

| 구분 (Class)     | 주요 모델 (Example)                      | 아키텍처 (Architecture)              | 프롬프트 이해 (Promptable?) | 입력 예시 (Input)                            | 출력 예시 (Output)                                     | 인프라 (Infra)            | 핵심 용도 (Use Case)                           |
| -------------- | ------------------------------------ | -------------------------------- | --------------------- | ---------------------------------------- | -------------------------------------------------- | ---------------------- | ------------------------------------------ |
| 1. NLU(이해 모델)  | BERT, Electra,RoBERTa                | Transformer Encoder Only(입력을 숫자로 압축)         | 불가능 (No)(명령어 인식 불가)   | "배터리가 너무 빨리 닳아요"(Raw Text)               | Label: 불만(Complaint)Score: 0.98                    | CPU / T4               | -  RAG 검색기 (Retriever)-  스팸/키워드 분류-  감성 분석 |
| 2. SLM(엣지 모델)  | Llama 3 8B, Phi-3,Gemma 2            | 	Transformer Decoder Only(다음 단어 예측/생성)        | 가능 (Yes)(지시 수행 가능)    | "배터리 절약 팁 3개 알려줘"(Instruction)           | "1. 화면 밝기 줄이기..."(Generated Text)                  | 노트북 / 엣지(M4, RTX 4090) | -  온디바이스 비서-  보안 문서 요약-  오프라인 번역           |
| 3. sLLM(중형 모델) | Llama 3 70B, Qwen 72B,Mixtral 8x7B   | 	Transformer Decoder Only                     | 가능 (Yes)              | "첨부된 매뉴얼 기반으로 답해"(Instruction + Context) | "매뉴얼 12페이지에 따르면..."(Grounded Text)                 | A100/H100(단일 서버)       | -  사내 전문 챗봇-  법률/의료 분석-  RAG 답변 생성         |
| 4. LLM(거대 모델)  | GPT-4, Claude 3,DeepSeek V3          | 	Transformer Decoder Only                     | 가능 (Yes)              | "이 코드 리팩토링하고 이유 설명해"(Complex Prompt)     | "```python def optimize()...```"(Code + Reasoning) | GPU 클러스터(Cloud API)    | -  복잡한 코딩-  논문 심층 분석-  창의적 글쓰기             |
| 5. LMM(멀티모달)   | GPT-4o, Gemini 1.5,Claude 3.5 Sonnet | Hybrid /Omni-Model(Visual/Audio Encoder) | 가능 (Yes)              | [이미지] "이거 얼마야?"(Image + Text)            | "사진 속 제품은 $20입니다."(Multi-modal)                    | 전용 AI 칩(TPU/LPU)       | -  실시간 음성 대화-  이미지 분석-  자율 에이전트            |


- Encoder vs Decoder 

| 아키텍처         | 핵심 동작 (Action)        | 비유 (Analogy)                          | 데이터 흐름                          |
| ------------ | --------------------- | ------------------------------------- | ------------------------------- |
| Encoder(압축기) | "정보를 이해하고 압축한다"       | 독해 시험: 지문을 읽고 핵심 내용이나 정답(번호)만 골라냄     | Text $\\rightarrow$ Vector/Label |
| Decoder(생성기) | "다음에 올 내용을 추측하여 생성한다" | 작문 시험: 앞 문장을 보고 뒤에 이어질 내용을 상상해서 글짓기 함 | Vector $\\rightarrow$ Text      |

<br>

***

<br>


## LLM 내부 동작원리 

- LLM 내부 동작을 6단계로 구분하여 정리

| 단계 (Step)          | 동작 (Action)  | 역할 (Description)                       | 입력 (Input)      | 출력 (Output)                          |
| ------------------ | ------------ | -------------------------------------- | --------------- | ------------------------------------ |
| 1단계Tokenization    | 텍스트 분해       | 문장을 모델이 이해하는 최소 단위(토큰 ID)로 쪼갠다.        | Text String"안녕" | List of Integers[3521, 102]          |
| 2단계Embedding       | 벡터 변환        | 정수 ID를 의미를 담은 고차원 숫자 배열(Vector)로 바꾼다.  | Token ID3521    | Dense Vector[0.12, -0.5, ...]        |
| 3단계Positional Enc. | 위치 주입        | 단어의 순서 정보(위치값)를 벡터에 더해준다.              | Vector          | Vector + Pos(위치 정보 포함됨)              |
| 4단계Transformer     | 문맥 추론(핵심 연산) | Self-Attention을 통해 단어 간의 관계와 문맥을 파악한다. | Context Vectors | Refined Vectors(문맥이 반영된 벡터)          |
| 5단계Prediction      | 확률 계산        | 다음에 올 가능성이 있는 모든 단어의 점수(Logits)를 매긴다.  | Final Vector    | Logits (Probability){"안녕": 90%, ...} |
| 6단계Decoding        | 선택 및 반복      | 확률에 따라 단어를 하나 골라 출력하고, 입력에 붙여 반복한다.    | Logits          | Next Token"하세요"                      |

### 상세 설명


#### **1단계: Tokenization (토큰화)**
> **"텍스트를 숫자로 된 ID 리스트로 변환"**

*   **동작:** 입력된 문장을 모델의 어휘 사전(Vocabulary)에 있는 단어 조각(Token)으로 분할
*   **예시:** `"도커가 뭐야?"` -> `["도커", "가", "뭐", "야", "?"]`
*   **결과:** `[ID: 101, ID: 2304, ID: 994, ...]`
*   **Engineering Note:** 여기서 `UNK(Unknown)` 토큰이 많이 뜨면 모델 성능이 낮아짐 -> 이 토크나이저 효율로 인해 한국어 전용 모델을 사용

#### **2단계: Embedding (임베딩)**
> **"ID를 의미를 가진 벡터(숫자 배열)로 변환"**

*   **동작:** 각 ID(정수)를 4096차원(Llama-3 기준)의 실수 벡터로 매핑
*   **예시:** `ID: 2304` -> `[0.01, -0.54, 0.33, ...]` (4096개의 숫자)
*   **의미:** 이 숫자들에 '도커'라는 단어의 의미(컨테이너, 가상화 등)가 압축되어 있는 형태

#### **3단계: Positional Encoding (위치 인코딩)**
> **"벡터에 순서(위치) 정보를 주입"**

*   **동작:** 임베딩된 벡터에 **"나는 첫 번째 단어야", "나는 두 번째야"**라는 위치 정보를 담은 벡터를 추가 (Add).
*   **이유:** `Transformer`는 병렬 처리 구조라 순서 알수 없음. "도커가 나를 만들었다"와 "내가 도커를 만들었다"를 구분하려면 이 단계가 필수적임
*   **최신 기술:** 최신 모델(Llama 3, Phi-3)은 단순 덧셈 대신 **RoPE(Rotary Positional Embeddings)**라는 회전 변환 방식을 써서 긴 문맥도 잘 기억할수 있음

#### **4단계: Transformer Block & Attention (핵심 추론)**
> **"문맥(Context)을 파악하고 단어 간의 관계 계산"**

*   **동작:** **Self-Attention(자기 주의)** 메커니즘이 동작
*   **과정:** "도커"라는 단어가 입력되었을 때, 문장 내의 다른 단어들과의 연관성을 계산
*   **결과:** 문맥에 따라 단어 벡터의 값이 정교하게 수정. (단순한 '단어'가 아니라 '문맥 속의 의미'로 진화)

#### **5단계: Prediction (예측)**
> **"다음에 올 단어의 확률 분포 계산"**

*   **동작:** Transformer를 통과한 최종 벡터를 **Linear Layer(선형 계층)**에 통과시켜, 사전에 있는 5만~12만 개 모든 토큰에 대한 점수(Logits)를 책정.
*   **예시 출력:**
    *   `"컨테이너"`: 45%
    *   `"가상화"`: 30%
    *   `"리눅스"`: 10%
    *   `"바나나"`: 0.0001%

#### **6단계: Loop & Decoding (생성 루프)**
> **"주사위를 굴려 단어를 선택하고 다시 입력으로 넣기"**

*   **Decoding Strategy:** 확률이 제일 높은 "컨테이너"를 선택할지(Greedy), 아니면 약간의 창의성을 발휘해 "가상화"를 선택할지(Temperature, Top-P) 결정.
*   **Loop (무한 반복):**
    1.  선택된 단어: `"컨테이너"`
    2.  새로운 입력: `"도커가 뭐야? 컨테이너"`
    3.  **다시 1단계~5단계 반복**
    4.  이 과정을 `[EOS]`(문장 끝) 토큰이 나올 때까지 수십 번 반복.

### **정리: 엔지니어가 봐야 할 포인트**

1.  **1~3단계(입력 처리):** 매우 빠르게 동작하며 비용이 거의 발생하지않음
2.  **4단계(Attention):**  문장이 길어지면 해당단계에서 메모리 OOM 발생으로 병목 발생
3.  **6단계(Loop):** 한 번에 한 글자밖에 못 쓰기 때문에, 긴 답변을 요구하면 이 무거운 루프를 수백 번 돌려야함. LLM 응답이 느린 직접적인 원인.


<br>

***

<br>

## 모델의 생애 주기 

| 시점                          | 누가?                | 무엇을?                    | 학습 방식                     | 상태                        |
| --------------------------- | ------------------ | ----------------------- | ------------------------- | ------------------------- |
| 1. 탄생(Pre-training)         | OpenAI / Meta(제조사) | GPU 1만 개로 인터넷 전체를 읽힘.   | 자기 지도 학습(Self-supervised) | Base Model(말은 잘하는데 멍청함)   |
| 2. 교육(Fine-tuning)          | OpenAI / Meta(제조사) | Q&A 데이터로 지시 따르기를 가르침.   | 지도 학습(SFT, RLHF)          | Instruct Model(말 잘 듣는 비서) |
| 3. 배포(Release)              | Hugging Face(공개)   | 우리 같은 개발자가 다운로드 받음.     | -                         | Llama-3-Instruct(완성품)     |
| 4. 활용(Inference)            | 나 (개발자)            | 내 데이터를 넣어서 결과를 뽑음.      | -                         | 학습 안 함(그냥 쓰기만 함)          |
| (옵션) 5. 재교육(My Fine-tuning) | 나 (개발자)            | 우리 회사 데이터로 '추가 교육'을 시킴. | 지도 학습(SFT)                | Custom Model(우리 회사 전용 AI) |


- 자기 지도 학습은 '제조사의 영역'
    - 개인이 하기엔 너무 고가 (전기세만 수십억 나옴)
    - 사용자는 주로 자기 지도 학습을 끝내놓은 **Pre-trained Model(사전 학습된 모델)**을 가져다 사용

- '지도 학습'은 남이 만든 똑똑한 모델(Base/Instruct)을 가져와서, 우리 데이터로 살짝만 더 가르치는 것(Fine-tuning)
    -  일반적인 AI 개발자의 업무


<br>

***

<br>

## 모델 학습 


### 유형별 모델 학습 분류

| 유형 (Type)                    | 핵심 정의 (One-liner)                                      | 데이터 형태 (Input)                | 대표 알고리즘/모델                                                                             | 주요 용도 (Use Case)                                                       | 엔지니어링 노트 (Note)                                                          |
| ---------------------------- | ------------------------------------------------------ | ----------------------------- | -------------------------------------------------------------------------------------- | ---------------------------------------------------------------------- | ------------------------------------------------------------------------ |
| 1. 지도 학습(Supervised)         | "정답지 보고 외우기"입력과 정답 쌍을 1:1로 매핑하여 학습함.                   | 문제($X$) + 정답($Y$)(이미지, "고양이") | -  Classification (SVM, 로지스틱)-  Regression (선형, 랜덤포레스트)-  LLM SFT (Instruction Tuning) | -  스팸 분류, 암 진단-  집값/주가 예측-  LLM 챗봇화 (지시 이행)                            | -  가장 성능이 좋지만 비쌈.-  현업 AI 프로젝트의 90%는 결국 이걸 잘하는 게 목표임.                    |
| 2. 비지도 학습(Unsupervised)      | "끼리끼리 묶기"정답 없이 데이터의 숨은 구조나 그룹을 찾아냄.                    | 문제($X$) Only(고객 로그 1TB)       | -  Clustering (K-Means)-  Dim Reduction (PCA)-  Anomaly Detection (Isolation Forest)   | -  고객 세분화 (마케팅)-  이상 징후/사기 탐지-  데이터 전처리 및 시각화                          | -  라벨링 비용 0원.-  단독 사용보다는 **지도 학습 전 단계(라벨링 자동화)**로 많이 씀.                  |
| 3. 준지도 학습(Semi-supervised)   | "하나를 배우고 열을 알기"소량의 정답으로 기준을 잡고, 나머지 무정답 데이터를 스스로 라벨링함. | 소량 정답 + 대량 무정답                | -  Self-training (Pseudo-labeling)-  GAN (생성적 적대 신경망)                                  | -  의료 영상 분석 (전문의 라벨링 비쌈)-  저자원 언어 번역                                   | -  가성비 최강 전략.-  '비지도 분류 -> 지도 학습' 파이프라인이 여기에 속함.                         |
| 4. 자기 지도 학습(Self-supervised) | "빈칸 채우기 놀이"데이터의 일부를 가리고(Mask) 그것을 맞추며 문맥을 배움.          | 무정답 데이터(데이터 자체가 정답)           | -  Masked LM (BERT)-  Causal LM (GPT, Llama)-  Contrastive (SimCLR)                    | -  LLM 사전 학습 (Pre-training)-  문맥/의미 이해 (Representation)-  NLU 기본 모델 생성 | -  LLM의 '두뇌'를 만드는 단계.-  엄청난 컴퓨팅 자원이 필요하며 주로 빅테크 기업이 수행함.                 |
| 5. 강화 학습(Reinforcement)      | "당근과 채찍"시행착오를 겪으며 보상(점수)을 최대화하는 행동을 배움.                | 환경(Env) + 보상(Reward)          | -  Q-Learning / DQN-  RLHF (PPO, DPO)                                                  | -  알파고 (게임/바둑)-  로봇 제어 (보행 학습)-  LLM 윤리/말투 교정                          | -  LLM의 '예절'을 가르치는 단계.-  지도 학습만으로 해결 안 되는 미묘한 뉘앙스(Human Preference)를 잡음. |




### 모델 학습 단계

| 단계 (Stage)                   | 학습 유형 (Type)                | 주체 (Who)          | 데이터 (Input)                     | 목표 (Goal)                           | 상태 (Status)               | 비유 (Analogy)               |
| ---------------------------- | --------------------------- | ----------------- | ------------------------------- | ----------------------------------- | ------------------------- | -------------------------- |
| 1. 사전 학습(Pre-training)       | ④ 자기 지도 학습(Self-supervised) | 제조사(Meta, Google) | Raw Text(인터넷 전체)정답 없음           | "지능의 탄생"언어 문법, 세계 지식, 논리력 습득        | Base Model(말은 잘하는데 멍청함)   | 대학 교육(전공 서적 1만 권 읽고 지식 쌓기) |
| 2. 지시 튜닝(Instruction Tuning) | ① 지도 학습(Supervised / SFT)   | 제조사(Meta, Google) | Q&A Pair(지시+답변)정답 있음            | "대화 능력 장착"질문에 답하고 명령을 수행하는 법 습득     | Instruct Model(일 잘하는 비서)  | 신입 연수(업무 매뉴얼과 시키는 일 배우기)   |
| 3. 인간 피드백(Alignment / RLHF)  | ⑤ 강화 학습(Reinforcement)      | 제조사(Meta, Google) | Preference(A보다 B가 좋아)점수(Reward) | "예절과 윤리 주입"사람이 선호하는 말투와 안전성 확보      | Chat Model(예의 바르고 안전한 비서) | 인성 교육(동료들과 잘 지내는 법 배우기)    |
| 4. 추가 학습(Fine-tuning)        | ① 지도 학습(Supervised)         | 사용자(나, 개발자)       | Custom Data(우리 회사 데이터)정답 있음     | "도메인 전문가 특화"특정 분야(법률, 의료, 사내 규정) 숙달 | Custom Model(우리 회사 전용 AI) | 부서 배치(우리 팀만의 업무 스타일 익히기)   |


- 예시 
    - Pre-training (④ 자기 지도): 인터넷 글을 읽으며 지식을 쌓음. (Base Model)
    - SFT (① 지도): Q&A 데이터를 보며 질문에 답하는 법을 배움. (Instruct Model)
    - RLHF (⑤ 강화): 사람의 피드백(점수)을 받으며 더 자연스러운 말투를 익힘. (Chat Model)

> "GPT는 ④자기 지도 학습으로 태어나서, ①지도 학습으로 말을 배우고, ⑤강화 학습으로 예절을 익혔습니다."



