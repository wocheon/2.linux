import json
from google.cloud import monitoring_v3
import pandas as pd
import datetime
import pytz

def fetch_metrics(config_file):
    # ğŸ”¹ ì„¤ì • íŒŒì¼ ì½ê¸°
    with open(config_file, "r") as file:
        config = json.load(file)

    project_id = config["project_id"]
    metrics = config["metrics"]
    output_prefix = config.get("output_prefix", "metrics")

    # GCP APIëŠ” UTC ê¸°ì¤€ì´ë¯€ë¡œ KST â†’ UTC ë³€í™˜
    kst = pytz.timezone("Asia/Seoul")
    utc = pytz.utc

        # ğŸ”¹ KST -> offset-aware datetime ê°ì²´ë¡œ ë³€í™˜
#    start_time_kst = datetime.datetime.fromisoformat(config["start_time_kst"])
#    end_time_kst = datetime.datetime.fromisoformat(config["end_time_kst"])
    start_time_kst = kst.localize(datetime.datetime.fromisoformat(config["start_time_kst"]))
    end_time_kst = kst.localize(datetime.datetime.fromisoformat(config["end_time_kst"]))

        # ğŸ”¹ Time offset ì ìš©
    start_time_offset = config.get("start_time_offset", 0)  # ì‹œì‘ ì‹œê°„ ì¡°ì • (ë¶„ ë‹¨ìœ„)
    end_time_offset = config.get("end_time_offset", 0)      # ì¢…ë£Œ ì‹œê°„ ì¡°ì • (ë¶„ ë‹¨ìœ„)

    # ğŸ”¹ ì‹œì‘ ì‹œê°„ê³¼ ì¢…ë£Œ ì‹œê°„ì— ê°ê° ì˜¤í”„ì…‹ ì ìš©
    adjusted_start_time_kst = start_time_kst - datetime.timedelta(minutes=start_time_offset)
    adjusted_end_time_kst = end_time_kst - datetime.timedelta(minutes=end_time_offset)

    # KST â†’ UTC ë³€í™˜
    start_time_utc = adjusted_start_time_kst.astimezone(utc)
    end_time_utc = adjusted_end_time_kst.astimezone(utc)

        # í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    client = monitoring_v3.MetricServiceClient()

        # ë°ì´í„°ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
    data_dict = {}

        # Config íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ
    for metric in metrics:
        metric_type = metric["metric_type"]
        filter_template = metric["filter_template"]
        label_key = metric["label_key"]
        alias = metric["alias"]

        # ì‹œê°„ ë²”ìœ„ ì„¤ì •
        interval = monitoring_v3.TimeInterval({
                "end_time": end_time_utc,
                "start_time": start_time_utc,
        })

        #  Cloud Monitoring APIì— ë³´ë‚¼ ìš”ì²­ ì„¤ì •
        request = {
            "name": f"projects/{project_id}",
            "filter": filter_template,
            "interval": interval,
            "view": monitoring_v3.ListTimeSeriesRequest.TimeSeriesView.FULL,
            "aggregation": {
                "alignment_period": {"seconds": 60},  # 1ë¶„ ë‹¨ìœ„ ì •ë ¬
                "per_series_aligner": monitoring_v3.Aggregation.Aligner.ALIGN_MEAN,
            },
        }

        # ë°ì´í„° ì¡°íšŒ
        print(f"â–¶ Metric ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘ : {alias} ({metric_type})")
        response = client.list_time_series(request=request)

        # ì‘ë‹µ ë°ì´í„° ì²˜ë¦¬ (UTC â†’ KST ë³€í™˜)
        for time_series in response:
            for point in time_series.points:
                timestamp_utc = point.interval.end_time
                timestamp_kst = timestamp_utc.astimezone(kst)  # KST ë³€í™˜
                if not (adjusted_start_time_kst <= timestamp_kst <= adjusted_end_time_kst):
                    continue

                timestamp_str = timestamp_kst.strftime("%Y-%m-%d %H:%M:%S")
                label_value = time_series.resource.labels.get(label_key, "unknown")

                key = (timestamp_str, label_value)
                if key not in data_dict:
                    data_dict[key] = {
                                                "timestamp": timestamp_str,
                        "date": timestamp_kst.strftime("%Y-%m-%d"),
                                                "time": timestamp_kst.strftime("%H:%M:%S"),
                                                "weekday": timestamp_kst.strftime("%A"),
                                                "label": label_value,
                                        }
                    data_dict[key][alias] = round(point.value.double_value, 2)

    df = pd.DataFrame(list(data_dict.values()))

        # Output fileì— timestampì»¬ëŸ¼ì´ ì¶œë ¥ë˜ì§€ì•Šë„ë¡ DROP
    df = df.drop(columns=["timestamp"])

        # ì •ë ¬
    df = df.sort_values(by=["date", "time", "weekday", "label"])

        # Output íŒŒì¼ëª…ì„ [íŒŒì¼ëª…]_[ì‹œì‘ì‹œê°„]_[ì¢…ë£Œì‹œê°„].csv í˜•íƒœë¡œ ë³€ê²½
    start_str = start_time_kst.strftime("%y%m%d")
    end_str = end_time_kst.strftime("%y%m%d")
    output_file = f"{output_prefix}_{start_str}_{end_str}.csv"

    df.to_csv(output_file, index=False)
    print(f"\nâœ… ì™„ë£Œ! ê²°ê³¼ íŒŒì¼ ì €ì¥ë¨: {output_file}")

if __name__ == "__main__":
                fetch_metrics("config.json")