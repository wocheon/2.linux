# modules/vector_cache.py

### ì„¤ì¹˜ í•„ìš” íŒ¨í‚¤ì§€
#pip install chromadb sentence-transformers
# Ollama ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© ì‹œ
#python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('all-MiniLM-L6-v2')"

import chromadb
from chromadb.utils import embedding_functions
import uuid
import logging

logger = logging.getLogger(__name__)

class VectorCache:
    def __init__(self, persist_path="./chroma_data", threshold=0.3):
        self.threshold = threshold
        
        logger.info("ğŸ“‚ Vector DB (ChromaDB) ì´ˆê¸°í™” ì¤‘...")
        
        self.client = chromadb.PersistentClient(path=persist_path)
        
        # ë¡œì»¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© (sentence-transformers)
        self.emb_fn = embedding_functions.SentenceTransformerEmbeddingFunction(
            model_name="all-MiniLM-L6-v2"
        )
        
        self.collection = self.client.get_or_create_collection(
            name="chat_response_cache",
            embedding_function=self.emb_fn,
            metadata={"hnsw:space": "cosine"}
        )
        logger.info("âœ… Vector DB ì¤€ë¹„ ì™„ë£Œ")

    # [ìˆ˜ì •] intent íŒŒë¼ë¯¸í„° ì¶”ê°€ ë° where ì¡°ê±´ ì ìš©
    def get(self, user_query, intent=None):
        try:
            # intentê°€ ìˆìœ¼ë©´ í•„í„°ë§, ì—†ìœ¼ë©´ ì „ì²´ ê²€ìƒ‰
            where_filter = {"intent": intent} if intent else None
            
            results = self.collection.query(
                query_texts=[user_query],
                n_results=1,
                where=where_filter  # [í•µì‹¬] ë©”íƒ€ë°ì´í„° í•„í„°ë§
            )
            
            if not results['ids'] or not results['distances'][0]:
                return None, None

            distance = results['distances'][0][0]
            cached_answer = results['metadatas'][0][0]['answer']

            if distance < self.threshold:
                logger.info(f"âš¡ Cache Hit! (Dist: {distance:.4f}, Intent: {intent})")
                return cached_answer, distance
            else:
                return None, None
                
        except Exception as e:
            logger.error(f"Cache Get Error: {e}")
            return None, None

    # [ìˆ˜ì •] intent íŒŒë¼ë¯¸í„° ì¶”ê°€ ë° ë©”íƒ€ë°ì´í„° ì €ì¥
    def set(self, user_query, ai_answer, intent="UNKNOWN"):
        try:
            if len(ai_answer) < 5 or "ì˜¤ë¥˜" in ai_answer:
                return

            # ë©”íƒ€ë°ì´í„°ì— intent ì¶”ê°€
            metadata = {"answer": ai_answer, "intent": intent}

            self.collection.add(
                ids=[str(uuid.uuid4())],
                documents=[user_query],
                metadatas=[metadata]
            )
            logger.info(f"ğŸ’¾ Cache Saved (Intent: {intent})")
        except Exception as e:
            logger.error(f"Cache Set Error: {e}")
    
    def clear(self):
        """ìºì‹œ ì „ì²´ ì‚­ì œ"""
        try:
            self.client.delete_collection("chat_response_cache")
            # ì‚­ì œ í›„ ì¬ìƒì„± (ì•ˆ ê·¸ëŸ¬ë©´ ë‹¤ìŒ í˜¸ì¶œ ë•Œ ì—ëŸ¬ ë‚¨)
            self.collection = self.client.create_collection(
                name="chat_response_cache",
                embedding_function=self.emb_fn,
                metadata={"hnsw:space": "cosine"}
            )
            logger.info("ğŸ§¹ Vector Cache Cleared")
        except Exception as e:
            logger.error(f"Cache Clear Error: {e}")